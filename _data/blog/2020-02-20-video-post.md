---
template: BlogPost
path: /muster
date: 2020-02-20T15:05:49.332Z
title: Post with Youtube Video embed
metaDescription: >-
  Muster is a mobile based platform which enables the users with different
  abilities to connect and have a seamless conversation. The design is aimed at
  supporting conversation in ASL, text, and spoken English one-on-one or with
  multiple people.
thumbnail: /assets/muster_30fps.svg
---
![overview of the app's main screens: live asl transcription and live asl interpreting](https://liamkiniry.site/assets/images/muster/toggle.png)

## Communication for all abilities

### Project Type:User Centered Design, UI Design, UX Design

### Date:Sep-Dec 2019

### Technologies:Figma, Photoshop, Illustrator

Muster is a mobile based platform which enables the users of all abilities to connect and have a seamless conversation. The design is aimed at supporting conversation in ASL, text, and spoken English. This application allows users to plan and set up meetings. Once a user joins a meeting, the product provides all the necessary feedback for the seamless conversation, through the media of speech, text, and an ASL relay service.

## The Challenge

We wanted to develop a design intervention that would allow fluid communication between deaf and hard of hearing individuals and hearing (DHH) people in the work place. Deaf and hard of hearing people face many challenges when communicating with their hearing colleagues. Our interviews with DHH people revealed issues around understanding hearing people, communicating, and social awkwardness:

“I feel pressure of approaching people to talk.”\
“It’s Difficult to focus attention in group settings compared to 1 on 1”\
“My voice and tone cannot be understood out via typing and texting or restricted facial expressions”\
“Trying to read lips can be inaccurate.”\
“I am afraid that having an interpreter with me might make things uncomfortable.”\
“Do they enjoy talking to me? Will them think I am weird?”\
“How can I express this technical terms to them”\
“How can I communicate with DHH people in the way they like.”\
“Do I convey my meanings? Do they understand?”\
“I like using ASL, it makes me comfortable!”\
“How can I let them know I am talking to them?”

## Understanding Users

In order to better understand what challenges Dead and Hard of Hearing professionals face when communicating with their hearing colleagues, and vice versa, we set up interviews with people who have range of abilities. Based on these interviews we developed three personas to represent key demographics from our target audience.

### Deaf and Hard of Hearing Users

From our interviews with Deaf and Hard of Hearing individuals we constructed this persona as a representative amalgamation of these users preferences, abilities, and barriers.

![This persona is a Deaf and hard of hearing user who works in the design field and prefers to use ASL when communicating. She feels much more comfortable expressing and explaining ideas using ASL.](https://liamkiniry.site/assets/images/muster/Linda.png)

### Hearing Users

This persona represents our findings from interviews with hearing individuals who do not know ASL. These individuals prefer to communicate in spoken English. They also feel awkwardness approaching people who communicate differently.

![This persona is a hearing user who works in technology and prefers to use spoken english to communicate.](https://liamkiniry.site/assets/images/muster/Ben.png)

### Hearing Users who use ASL

Some of the hearing people we interviewed knew ASL. This persona represents a hearing user who knows a significant amount of ASL. They are confident sharing ideas in spoken English and ASL but may need assistance when using ASL to convey complex ideas and jargon.

![This persona is a hearing user who knows a significant amount of ASL. She is confident sharing ideas in spoken english and ASL but may need assistance when using ASL.](https://liamkiniry.site/assets/images/muster/Rachel.png)

## Ideation

### Sketching

We used the information we gathered from our expert users to start developing ideas for design solutions. We began to make quick sketches to documents all the ideas we had come up with. We made a total of 150 small sketches some of which were very outlandish like wigs that spelled out the words people were saying. This stage was very helpful in exploring potential solutions to our users' challenges and some of these sketches influenced our design.

![This shows a series of sketches including ideas like VR interpreting services, multimodal notifications.](https://liamkiniry.site/assets/images/muster/sketches.png)

![This shows our refined sketch that includes a table interface and a mobile interface enabling users to communicate and receive translation and transcription in front of them.It includes emoji to convey tone, speakers to allow for text to speech, LEDs to notify DHH users, cameras to capture ASL video input. It also includes a chat bubble like interface that our expert user states was easily understood and looked fun.](https://liamkiniry.site/assets/images/muster/sketchfinal.jpg)

### Iteration and Development

We brought sketches of our best ideas to the potential users we had interviewed and asked them for feedback.\
We gathered the following needs to account for in our design based on our interview with our expert users:\
- Conveys Emotion (tone +voice)\
- Ease of introduction and nervousness\
- Translates between ASL, Spoken English, written English\
- Professional application\
- Functional in Group setting and 1-1\
- No extra or complicated devices\
- Focus on wearable + mobile\
- Implementable /feasible / realistic (can we prototype it?)\
We merged the best part of our design ideas and incorporated the feedback from our expert users into this refined sketch that fit the needs and criteria of our users.

![This sketch shows the design of the chat interface for users](https://liamkiniry.site/assets/images/muster/detailsketch.jpeg)

## Designing Interactions

### Storyboarding

In order to think critically about the lifecycle of interaction with our design solution we sketched out a storyboard how the average person would use our system. This allowed us to break up the interaction with the app into stages: before the meeting, during the meeting, and after the meeting.

![ This image shows a sketch in the style of a comic strip of how a person would use the app in planning and carrying out a meeting.](https://liamkiniry.site/assets/images/muster/storyboard.png)

### Iterative Prototyping

We developed a paper prototype of our design to lock down our key features and developed fully fleshed out interactions. The paper prototype was achieved by sketching out storyboard of the use cases we were prototyping. We used post-its for interactions like ‘Add’, ‘Delete’, ‘Message Box’, ‘Pop-ups’ and ‘Notifications’. We invited our expert users to come and test out our paper prototype in order to understand our users' impressions of the system and get feedback on the basic functionality of our design. From this testing we were able to understand that some of our components in the Video Relay translation Service needed to be labeled more clearly. We used the feedback from this session to iterate on our design and build a high fidelity prototype.

![This image shows photo of all of the paper prototype componenets of our design.](https://liamkiniry.site/assets/images/muster/paperprototype.jpeg)

## The Final Design

![This shows the landing page and login for the muster app.](https://liamkiniry.site/assets/images/muster/musterbegin.png)

### Overview

Our users needed a system that enabled fluid conversation between people who have different abilities. We decided integrate this functionality in a multipurpose system so that accessibility could become a part of everyday practice. We developed this conceptual model of our design:\
Our design is a multi-modal communication tool for enabling fluid, real-time communication and collaboration between DHH and hearing individuals. In this case multi-modal means that our project enables a real-time conversion between ASL, text and verbal medium of communication crafted as per the abilities of our users. Our design is a system intended to create a virtual collaborative space using users’ individual mobile phones(shown below), all synced with each other, and translating the entire conversation in the meeting room in the form of textual chat(2). Additionally, the system provides a live translation to every user individually as per their preferences (spoken English, ASL-interpreter(1), or text). The system also provides ambient visual, tactile, and sonic notifications(3).

![This sketch shows the design of the chat interface for users](https://liamkiniry.site/assets/musterIllustration.svg)

## Key Features

Muster lets users plan and set up official meetings with and invite people. It utilizes the knowledge of user's preferences to set up a conducive environment for users to communicate. It enables DHH users communicate in ASL. Users are provided with a real-time text transcript of conversation. Muster uses visual feedback to highlight to DHH users who’s speaking and the tone of the speaker. After the meeting users can access and share the transcript of the meeting.\
The app has four main functionalities

1. SCHEDULE MEETINGS
2. FLUENT MEETING
3. DOCUMENT MANAGEMENT
4. SHARING MEETING INFO

### Schedule Meetings

The landing page displays all the upcoming meetings scheduled by the users on the app. The meeting list is kept as the landing page because it is the most frequently accessed feature of the App. The tiles on the landing page provides to the user the direct access to the upcoming meeting while the other section can be accessed using the hamburger menu on the left side.\
Here users can plan and schedule meetings. Users select the time, date and location of the meeting, gives a title and invites the people to connect. Once the meeting is created every added member receives the invites and the notification reminder of the same using the App push notifications.

![This GIF shows the interaction of users creating and setting a meeting in the system](https://liamkiniry.site/assets/images/muster/createmeeting.gif)

### Fluent Meeting

Users can join a meeting and connect for a seamless conversation. The system provides the user with a live text transcript and a live ASL interpretation (through Video Relay Service) of the entire conversation. Users can toggle sections of the system on and off based on their preferred modes of communication. DHH users who do not know ASL can toggle off the VRS service, for example. Users can also leave at any time from this meeting.

![This GIF shows an example of how users recieve translation between languages during a meeting.](https://liamkiniry.site/assets/images/muster/chat1.gif)

### Document Management

Users can dynamically upload documents to the chat from file management systems on their device like google drive. The system keeps these documents in the meeting log so they can be accessed at any time during or after the meeting.

![this GIF shows the process of uploading documents to a meeting](https://liamkiniry.site/assets/images/muster/sharedoc.gif)

### Sharing Meeting Info

The system records a transcript of the meeting along with any documents that were a part of the meeting for users to reference and share. Users can share these documents and make comments.

![This GIF shows how users can share and view documents after the meeting](https://liamkiniry.site/assets/images/muster/transcriptview.gif)

### Customizable

Users can customize the system to communicate in their preferred methods. Different sections can be toggles on and off to suit the users' ideal interactions.

![this image shows the VRS and Chat elements that users can toggle on and off](https://liamkiniry.site/assets/images/muster/toggle.png)

## User Testing

![This photo shows one of the user testing participants gesturing towards the prototype](https://liamkiniry.site/assets/images/muster/usertesting.jpg)

We brought this prototype to our expert users and asked them to complete some basic tasks like setting a meeting, having a mock conversation, and sharing documents. We were able to receive a lot of useful feedback from our expert users. We were able to see that there were some problems having a real time conversation with the mocked VRS. We were able to learn that most of our icons and interactions could be understood. We were also able to learn more about the testing experience.

![an image showing a mockup of the app in action on a table at a meeting](https://liamkiniry.site/assets/images/muster/insitu.png "an image showing a mockup of the app in action on a table at a meeting")

> "I think it worked pretty well."

\- A Participant in our User Testing

## Reflection

This project gave me the experience of ideating and prototyping a user centered design project. It was nice to learn techniques in this project that I could apply to new challenges. I also learned a lot about the process of user testing and some techniques when dealing with specialized audiences. Mostly its about making people as comfortable as possible. I was also nice to be able to design a holistic system that has the potential to improve the lives of deaf and hard of hearing people.
